1、为什么使用缓存？
在高并发请求时，为何我们频繁提到缓存技术？最直接的原因是，磁盘IO及网络开销是直接请求内存IO千百上千倍，做个简单计算，
如果我们需要某个数据，该数据从数据库磁盘读出来需要0.0045S，经过网络请求传输需要0.0005S，那么每个请求完成最少需要0.005S，
该数据服务器每秒最多只能响应200个请求，而如果该数据存于本机内存里，读出来只需要100us，那么每秒能够响应10000个请求。
通过将数据存储到离CPU更近的未位置，减少数据传输时间，提高处理效率，这就是缓存的意义。

2、缓存收益成本对比？
收益
1.1 加速读写。因为缓存通常都是全内存的系统，而后端（可能是mysql、HTTP、RPC接口）都有速度慢和抗压能力差的特性，
通过缓存的使用可以有效提高用户的访问速度同时优化用户体验。
1.2 降低后端负载。通过添加缓存，如果程序没有什么问题，在命中率还可以的情况下，可以帮助后端减少访问量和复杂计算(join、或者无法在优化的sql等)，
很大程度降低了后端的负载。
成本
2.1 数据不一致性。无论设计做的多么好，缓存数据与真实数据源一定存在着一定时间窗口的数据不一致性，时间窗口可大可小，具体多大还要看一下业务允许多大时间窗口的不一致性。
2.2 代码维护成本。有缓存后，代码就会在原数据源基础上加入缓存的相关代码，例如原来只是一些sql，现在要加入k-v缓存，必然增加代码维护成本。
2.3 架构复杂度。有缓存后，需要专职管理人员来维护主从缓存系统，同时也增加了架构的复杂度和维护成本。

3、高并发场景下带来常见问题？
(1) 缓存一致性
(2) 缓存并发（缓存击穿）
(3) 缓存穿透
(4) 缓存雪崩（缓存失效）

4、缓存一致性问题
当数据时效性要求很高时，需要保证缓存中的数据与数据库中的保持一致，而且需要保证缓存节点和副本中的数据也保持一致，不能出现差异现象。
这就比较依赖缓存的过期和更新策略。一般会在数据发生更改的时，主动更新缓存中的数据或者移除对应的缓存。

5、缓存并发问题
对于一些设置了过期时间的key，可能这些key会在某些时间点被超高并发地访问，是一种非常“热点”的数据。
这个时候，需要考虑缓存被“击穿”的问题，和缓存雪崩的区别在于这里针对某一key缓存，而缓存雪崩则是很多key。
解决方案:导致问题的原因是同一时间查，同一时间写缓存，导致并发下缓存也没用，所以考虑使用单线程等方法将写缓存保证只有一个去查了写，
其他的使用缓存。业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值是否为空），不是立即去loaddb，
而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，
再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。SETNX是[SET if Not eXists]的缩写，也就是只有不存在的时候才设置，
可以利用它来实现锁的效果。
1）使用互斥锁(mutex key)  该方案思路比较简单，就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以
2）“提前”使用互斥锁(mutex key)  即在value内部设置1个超时值(timeout1), timeout1比实际的redis timeout(timeout2)小。
当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中
缓存”永不过期“
(1) 从redis上看，不设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
(2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，
通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期。

6、缓存穿透问题
缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，
这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，要是DB无法承受瞬间流量冲击，DB可能就挂了
解决方案：有多种方法可以有效解决缓存穿透问题，一种比较简单粗暴的方法采用缓存空数据，如果一个查询返回的数据为空（数据库中不存在该数据），
仍然把这个空结果进行缓存（过期时间一般较短）。另一种方法则是采用常用的布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，
一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力

7、缓存雪崩问题
（1）由于Cache层承载着大量请求，DB层调用量实际很低，有效的保护了DB层(通常认为此层抗压能力稍弱)。
（2）如果Cache层由于某些原因(宕机、cache服务挂了或者不响应了)整体crash掉了，也就意味着所有的请求都会达到DB层，
所有DB的调用量会暴增，所以它有点扛不住了，甚至也会挂掉。
1.保证Cache服务高可用性。和飞机都有多个引擎一样，如果我们的cache也是高可用的，即使个别实例挂掉了，影响不会很大（主从切换或者可能会有部分流量到了后端），实现自动化运维。
2.依赖隔离组件为后端限流。其实无论是cache或者是mysql、hbase、甚至别人的RPC都会出现问题，我们可以将这些视同为资源，作为并发量较大的系统，假如有一个资源不可访问了，即使设置了超时时间，依然会hold住所有线程，造成其他资源和接口也不可以访问
3.提前演练预估。在项目上线前，通过演练，观察cache crash后，整体系统和DB的负载，提前做好预案